{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.condifition_diffusion.ddpm import DDPM\n",
    "from src.condifition_diffusion.unet import UNet\n",
    "from src.data.mnist import get_mnist_loader_and_transform\n",
    "from src.data.cifar10 import get_cifar10_loader_and_transform\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from src.condifition_diffusion.train import train\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.backends\n",
    "import torch.backends.mps\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 400\n",
    "dataset = \"cifar10\" # can be \"cifar10\" or \"mnist\"\n",
    "\n",
    "PATH_TO_READY_MODEL = None # input path for ready model\n",
    "\n",
    "PATH_TO_SAVE_MODEL = \"model.pth\"\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# For Mac OS\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "if dataset == \"mnist\":\n",
    "    data = get_mnist_loader_and_transform()\n",
    "elif dataset == \"cifar10\":\n",
    "    data = get_cifar10_loader_and_transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpm = DDPM(\n",
    "    T = T,\n",
    "    p_cond=0.2,\n",
    "    eps_model=UNet(\n",
    "        in_channels=data.in_channels,\n",
    "        out_channels=data.out_channels,\n",
    "        T=T+1,\n",
    "        num_classes=data.num_classes\n",
    "    ),\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train or load ready model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss for epoch 0: 0.9141:   1%|          | 3/469 [00:08<22:50,  2.94s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 17\u001b[0m\n\u001b[1;32m      5\u001b[0m model_with_time \u001b[38;5;241m=\u001b[39m DDPM(\n\u001b[1;32m      6\u001b[0m     T \u001b[38;5;241m=\u001b[39m T,\n\u001b[1;32m      7\u001b[0m     p_cond\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m data \u001b[38;5;241m=\u001b[39m get_mnist_loader_and_transform()\n\u001b[0;32m---> 17\u001b[0m _, val_losses \u001b[38;5;241m=\u001b[39m train(\n\u001b[1;32m     18\u001b[0m   model\u001b[38;5;241m=\u001b[39mmodel_with_time,\n\u001b[1;32m     19\u001b[0m   optimizer\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(params\u001b[38;5;241m=\u001b[39mmodel_with_time\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-4\u001b[39m),\n\u001b[1;32m     20\u001b[0m   epochs\u001b[38;5;241m=\u001b[39mEPOCHS,\n\u001b[1;32m     21\u001b[0m   device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     22\u001b[0m   train_dataloader\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mtrain_loader,\n\u001b[1;32m     23\u001b[0m   val_dataloader\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mval_loader\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     26\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(val_losses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith time\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n",
      "File \u001b[0;32m~/Projects/ai-projects/stable diffusion from scratch/stable diffusion from scratch/src/condifition_diffusion/train.py:29\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, epochs, device, train_dataloader, val_dataloader)\u001b[0m\n\u001b[1;32m     25\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     27\u001b[0m loss \u001b[38;5;241m=\u001b[39m model(imgs, labels)\n\u001b[0;32m---> 29\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     31\u001b[0m training_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch_gpu_m1/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch_gpu_m1/lib/python3.9/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if PATH_TO_READY_MODEL is not None:\n",
    "    ddpm.load_state_dict(torch.load(PATH_TO_READY_MODEL, map_location=device))\n",
    "else:\n",
    "    _, val_losses = train(\n",
    "        model=ddpm,\n",
    "        optimizer=torch.optim.Adam(params=ddpm.parameters(), lr=2e-4),\n",
    "        epochs=EPOCHS,\n",
    "        device=device,\n",
    "        train_dataloader=data.train_loader,\n",
    "        val_dataloader=data.val_loader\n",
    "    )\n",
    "\n",
    "    path = PATH_TO_SAVE_MODEL if PATH_TO_SAVE_MODEL is not None else \"model.pth\"\n",
    "\n",
    "    torch.save(ddpm.state_dict(), path)\n",
    "\n",
    "    plt.plot(val_losses, label=\"Validation Loss\")\n",
    "\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "number of dims don't match in permute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      2\u001b[0m x_t \u001b[38;5;241m=\u001b[39m ddpm\u001b[38;5;241m.\u001b[39msample(\n\u001b[1;32m      3\u001b[0m     n_samples\u001b[38;5;241m=\u001b[39mn_samples,\n\u001b[1;32m      4\u001b[0m     size\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mtrain_dataset[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape,\n\u001b[1;32m      5\u001b[0m     classes\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m9\u001b[39m],\n\u001b[1;32m      6\u001b[0m     w\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 8\u001b[0m x_t \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mtransform_to_pil(x_t)\n\u001b[1;32m      9\u001b[0m grid \u001b[38;5;241m=\u001b[39m make_grid(x_t, nrow\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     10\u001b[0m save_image(grid, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/ai-projects/stable diffusion from scratch/stable diffusion from scratch/src/data/mnist.py:11\u001b[0m, in \u001b[0;36mMNISTTransformation.__call__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: number of dims don't match in permute"
     ]
    }
   ],
   "source": [
    "n_samples = 10\n",
    "x_t = ddpm.sample(\n",
    "    n_samples=n_samples,\n",
    "    size=data.train_dataset[0][0].shape,\n",
    "    classes=[0,1,2,3,4,5,6,7,8,9],\n",
    "    w=0.2\n",
    ")\n",
    "result = []\n",
    "for i in range(x_t.shape[0]):\n",
    "    result.append(data.transform_to_pil(x_t[i]))\n",
    "\n",
    "grid = make_grid(x_t, nrow=10)\n",
    "save_image(grid, f\"sample.png\")\n",
    "\n",
    "cols = 5\n",
    "rows = (n_samples // cols) + (0 if n_samples % cols == 0 else 1)\n",
    "fig, axs = plt.subplots(rows, cols, figsize=(3 * cols, 3 * rows))\n",
    "for i in range(len(result)):\n",
    "    row = i // cols\n",
    "    axs[row, i % cols].imshow(result[i], cmap='gray' if dataset == \"mnist\" else None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "IGNORE_TIME_EMB = True\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int):\n",
    "        super().__init__()\n",
    "        self.ln = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.ln(x)\n",
    "\n",
    "class DoubleConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, emb_dim, is_debug=False):\n",
    "        super().__init__()\n",
    "        self.conv_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1),\n",
    "            nn.GroupNorm(8, out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.conv_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, padding=1),\n",
    "            nn.GroupNorm(8, out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.time_emb = MLP(input_dim=emb_dim, output_dim=out_channels)\n",
    "        self.is_debug = is_debug\n",
    "\n",
    "    def forward(self, x, t, has_attn = False):\n",
    "        x = self.conv_1(x)\n",
    "        if IGNORE_TIME_EMB:\n",
    "            return self.conv_2(x)\n",
    "        t = self.time_emb(t)\n",
    "        batch_size, emb_dim = t.shape \n",
    "        t = t.view(batch_size, emb_dim, 1, 1)\n",
    "        return self.conv_2(x + t)\n",
    "    \n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, T: int, output_dim: int) -> None:\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        position = torch.arange(T).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, output_dim, 2) * (-math.log(10000.0) / output_dim))\n",
    "        pe = torch.zeros(T, output_dim)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.pe[x].reshape(x.shape[0], self.output_dim)\n",
    "\n",
    "# print(PositionalEmbedding(2,4)(torch.tensor([[1], [0], [0]])))\n",
    "# torch.tensor([[1,2,3], [4,5,6], [7,8,9]])[ torch.tensor([[1], [0], [1]]) ].reshape(3, 3)\n",
    "\n",
    "# print( DoubleConvBlock(1, 16, 4)(torch.rand(2, 1, 28, 28), torch.rand(2, 4)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, emb_dim, is_debug=False):\n",
    "        super().__init__()\n",
    "        self.conv = DoubleConvBlock(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            emb_dim=emb_dim,\n",
    "            is_debug=is_debug\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.is_debug = is_debug\n",
    "    def forward(self, x, t):\n",
    "        x = self.conv(x, t)\n",
    "        return self.pool(x)\n",
    "    \n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, emb_dim, is_debug=False):\n",
    "        super().__init__()\n",
    "        self.upscale = nn.ConvTranspose2d(in_channels=in_channels, out_channels=in_channels, kernel_size=2, stride=2)\n",
    "        self.conv = DoubleConvBlock(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            emb_dim=emb_dim,\n",
    "            is_debug=is_debug\n",
    "        )\n",
    "        self.is_debug = is_debug\n",
    "    \n",
    "    def forward(self, x, skip, t):\n",
    "        x = self.upscale(torch.cat([x, skip], 1))\n",
    "        return self.conv(x, t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, T, hid_size = 256, is_debug = False):\n",
    "        super().__init__()\n",
    "\n",
    "        time_emb_dim = hid_size * 4\n",
    "        self.time_embedding = nn.Sequential(\n",
    "            PositionalEmbedding(T=T, output_dim=hid_size),\n",
    "            nn.Linear(hid_size, time_emb_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hid_size * 4, time_emb_dim)\n",
    "        )\n",
    "\n",
    "        self.is_debug = is_debug\n",
    "        self.down_1 = DownBlock(in_channels=in_channels, out_channels=hid_size, emb_dim=time_emb_dim)\n",
    "        self.down_2 = DownBlock(in_channels=hid_size, out_channels=hid_size * 2, emb_dim=time_emb_dim)\n",
    "        # self.resnet_left_3 = ResnetBlock(in_channels=hid_size * 2, out_channels=hid_size * 4)\n",
    "        # self.down_3 = nn.MaxPool2d(kernel_size=2, return_indices=True)\n",
    "\n",
    "        self.backbone = DoubleConvBlock(in_channels=hid_size * 2, out_channels=hid_size * 2, emb_dim=time_emb_dim)\n",
    "\n",
    "        # self.up_1 = nn.ConvTranspose2d(in_channels=hid_size * 4, out_channels=hid_size * 4, kernel_size=2, stride=2)\n",
    "        # self.resnet_right_1 = ResnetBlock(in_channels=hid_size * 4, out_channels=hid_size * 2)\n",
    "        self.up_2 = UpBlock(in_channels=hid_size * 4, out_channels=hid_size, emb_dim=time_emb_dim)\n",
    "        self.up_3 = UpBlock(in_channels=hid_size * 2, out_channels=hid_size, emb_dim=time_emb_dim)\n",
    "        self.out = nn.Conv2d(in_channels=hid_size, out_channels=out_channels, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        time_emb = self.time_embedding(t)\n",
    "\n",
    "        down_1 = self.down_1(x, time_emb)\n",
    "        if self.is_debug:\n",
    "            print(\"Down 1 shape:\", down_1.shape)\n",
    "        down_2 = self.down_2(down_1, time_emb)\n",
    "        if self.is_debug:\n",
    "            print(\"Down 2 shape:\", down_2.shape)\n",
    "        # x_3 = self.resnet_left_3(x)\n",
    "        # if self.is_debug:\n",
    "        #     print(\"Resnet left 3 shape:\", x_3.shape)\n",
    "        # x, ind_3 = self.down_3(x_3)\n",
    "        # if self.is_debug:\n",
    "        #     print(\"Down 3 shape:\", x.shape)\n",
    "        \n",
    "        # if self.is_debug:\n",
    "        #     print(\"Time:\", t.shape)\n",
    "        # batch_size, dim = time_emb.shape\n",
    "        # time_emb = time_emb.view(batch_size, dim, 1, 1)\n",
    "        # if self.is_debug:\n",
    "        #     print(\"Time embedding:\", time_emb.shape)\n",
    "        # x = self.backbone(x + time_emb)\n",
    "        x = self.backbone(down_2, time_emb)\n",
    "        \n",
    "        # x = self.up_1(x, indices = ind_3)\n",
    "        # if self.is_debug:\n",
    "        #     print(\"Up 1 shape:\", x.shape)\n",
    "        # x = self.resnet_right_1(x + x_3)\n",
    "        # if self.is_debug:\n",
    "        #     print(\"Resnet right 1 shape:\", x.shape)\n",
    "        x = self.up_2(x, down_2, time_emb)\n",
    "        if self.is_debug:\n",
    "            print(\"Up 2 shape:\", x.shape)\n",
    "        x = self.up_3(x, down_1, time_emb)\n",
    "        if self.is_debug:\n",
    "            print(\"Up 1 shape:\", x.shape)\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "# test_unet = UNet(in_channels=1, out_channels=1, T=100, is_debug=True)\n",
    "# test_unet(torch.rand(3, 1, 28, 28), torch.randint(1, 100, (3,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "# Collect garbage\n",
    "gc.collect()\n",
    "\n",
    "# Empty the PyTorch cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_to_tensor = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "class UnNormalize(torch.nn.Module):\n",
    "    def __init__(self, mean, std) -> None:\n",
    "        super().__init__()\n",
    "        self.mean = torch.tensor(mean)\n",
    "        self.std = torch.tensor(std)\n",
    "    \n",
    "    def forward(self, tensor):\n",
    "        mean = self.mean.to(tensor.device)\n",
    "        std = self.std.to(tensor.device)\n",
    "        \n",
    "        # Clone the input tensor to avoid modifying the original tensor\n",
    "        tensor = tensor.clone()\n",
    "        \n",
    "        # Apply the un-normalization\n",
    "        unnormalized_tensor = tensor * std[:, None, None] + mean[:, None, None]\n",
    "        \n",
    "        return unnormalized_tensor\n",
    "    \n",
    "transform_to_pil = transforms.Compose([\n",
    "    # UnNormalize(mean=[0.5], std=[0.5]),\n",
    "    transforms.ToPILImage()\n",
    "])\n",
    "\n",
    "# plt.imshow(transform_to_pil(train_dataset[0][0]), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torchvision' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mMNIST(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./datasets\u001b[39m\u001b[38;5;124m\"\u001b[39m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39mtransform_to_tensor)\n\u001b[1;32m      2\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      4\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mMNIST(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./datasets\u001b[39m\u001b[38;5;124m\"\u001b[39m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39mtransform_to_tensor, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torchvision' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root=\"./datasets\", download=True, transform=transform_to_tensor)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root=\"./datasets\", download=True, transform=transform_to_tensor, train=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE MPS\n"
     ]
    }
   ],
   "source": [
    "import torch.backends\n",
    "import torch.backends.mps\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "    print(\"USE MPS\")\n",
    "    # test_unet = UNet(in_channels=1, out_channels=1, is_debug=True).to(device)\n",
    "    # test_unet(train_dataset[0][0].unsqueeze(0).to(device), torch.tensor([[1]], dtype=torch.float, device=device))\n",
    "\n",
    "# import os\n",
    "# os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPM(nn.Module):\n",
    "    def __init__(self, T: int, nn_model: nn.Module):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        self.nn_model = nn_model.to(device)\n",
    "        beta_schedule = torch.linspace(1e-4, 0.02, T + 1, device=device)\n",
    "        alpha_t_schedule = 1 - beta_schedule\n",
    "        bar_alpha_t_schedule = torch.cumprod(alpha_t_schedule.detach().cpu(), 0).to(device)\n",
    "        sqrt_bar_alpha_t_schedule = torch.sqrt(bar_alpha_t_schedule)\n",
    "        sqrt_minus_bar_alpha_t_schedule = torch.sqrt(1 - bar_alpha_t_schedule)\n",
    "        self.register_buffer(\"beta_schedule\", beta_schedule)\n",
    "        self.register_buffer(\"alpha_t_schedule\", alpha_t_schedule)\n",
    "        self.register_buffer(\"bar_alpha_t_schedule\", bar_alpha_t_schedule)\n",
    "        self.register_buffer(\"sqrt_bar_alpha_t_schedule\", sqrt_bar_alpha_t_schedule)\n",
    "        self.register_buffer(\"sqrt_minus_bar_alpha_t_schedule\", sqrt_minus_bar_alpha_t_schedule)\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, imgs):\n",
    "        t = torch.randint(low=1, high=self.T+1, size=(imgs.shape[0],), device=device)\n",
    "        noise = torch.randn_like(imgs, device=device)\n",
    "        batch_size, channels, width, height = imgs.shape\n",
    "        noise_imgs = self.sqrt_bar_alpha_t_schedule[t].view((batch_size, 1, 1 ,1)) * imgs \\\n",
    "            + self.sqrt_minus_bar_alpha_t_schedule[t].view((batch_size, 1, 1, 1)) * noise\n",
    "        \n",
    "        pred_noise = self.nn_model(noise_imgs, t.unsqueeze(1))\n",
    "\n",
    "        return self.criterion(pred_noise, noise)\n",
    "    \n",
    "    def sample(self, n_samples, size):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            x_t = torch.randn(n_samples, *size, device=device)\n",
    "            for t in range(self.T, 0, -1):\n",
    "                z = torch.randn_like(x_t, device=device) if t > 0 else 0\n",
    "                t_tensor = torch.tensor([t], device=device).repeat(x_t.shape[0], 1)\n",
    "                pred_noise = self.nn_model(x_t, t_tensor)\n",
    "                x_t = 1 / torch.sqrt(self.alpha_t_schedule[t]) * \\\n",
    "                    (x_t - pred_noise * (1 - self.alpha_t_schedule[t]) / self.sqrt_minus_bar_alpha_t_schedule[t]) + \\\n",
    "                    torch.sqrt(self.beta_schedule[t]) * z\n",
    "            x_t = x_t*-1 + 1\n",
    "            return x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: DDPM, optimizer: torch.optim.Optimizer, epochs: int):\n",
    "    training_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train(True)\n",
    "        training_loss = 0\n",
    "        val_loss = 0\n",
    "        pbar = tqdm.tqdm(train_dataloader)\n",
    "        for index, (imgs, labels) in enumerate(pbar):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            imgs = imgs.to(device)\n",
    "    \n",
    "            loss = model(imgs)\n",
    "    \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.item()\n",
    "            pbar.set_description(f\"loss for epoch {epoch}: {training_loss / (index + 1):.4f}\")\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for (imgs, labels) in test_dataloader:\n",
    "                imgs = imgs.to(device)\n",
    "                \n",
    "                loss = model(imgs)\n",
    "        \n",
    "                val_loss += loss.item()\n",
    "        training_losses.append(training_loss / len(train_dataset))\n",
    "        val_losses.append(val_loss / len(test_dataset))\n",
    "    return training_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss for epoch 0: 1.4783:   4%|▎         | 17/469 [00:20<09:15,  1.23s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [49], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m IGNORE_TIME_EMB \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model_without_time \u001b[38;5;241m=\u001b[39m DDPM(T \u001b[38;5;241m=\u001b[39m T, nn_model\u001b[38;5;241m=\u001b[39mUNet(in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, out_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, T\u001b[38;5;241m=\u001b[39mT))\n\u001b[0;32m----> 5\u001b[0m _, val_losses_without \u001b[38;5;241m=\u001b[39m train(\n\u001b[1;32m      6\u001b[0m   model_without_time,\n\u001b[1;32m      7\u001b[0m   torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(params\u001b[38;5;241m=\u001b[39mmodel_without_time\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-4\u001b[39m),\n\u001b[1;32m      8\u001b[0m   EPOCHS\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     11\u001b[0m IGNORE_TIME_EMB \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     12\u001b[0m model_with_time \u001b[38;5;241m=\u001b[39m DDPM(T \u001b[38;5;241m=\u001b[39m T, nn_model\u001b[38;5;241m=\u001b[39mUNet(in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, out_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, T\u001b[38;5;241m=\u001b[39mT))\n",
      "Cell \u001b[0;32mIn [45], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, epochs)\u001b[0m\n\u001b[1;32m     12\u001b[0m imgs \u001b[38;5;241m=\u001b[39m imgs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m model(imgs)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     18\u001b[0m training_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch_gpu_m1/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch_gpu_m1/lib/python3.9/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "T = 400\n",
    "\n",
    "IGNORE_TIME_EMB = True\n",
    "model_without_time = DDPM(T = T, nn_model=UNet(in_channels=1, out_channels=1, T=T+1))\n",
    "_, val_losses_without = train(\n",
    "  model_without_time,\n",
    "  torch.optim.Adam(params=model_without_time.parameters(), lr=2e-4),\n",
    "  EPOCHS\n",
    ")\n",
    "\n",
    "IGNORE_TIME_EMB = False\n",
    "model_with_time = DDPM(T = T, nn_model=UNet(in_channels=1, out_channels=1, T=T+1))\n",
    "_, val_losses = train(\n",
    "  model_with_time,\n",
    "  torch.optim.Adam(params=model_with_time.parameters(), lr=2e-4),\n",
    "  EPOCHS\n",
    ")\n",
    "\n",
    "plt.plot(val_losses_without, label=\"without time\")\n",
    "plt.plot(val_losses, label=\"with time\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IGNORE_TIME_EMB = True\n",
    "\n",
    "n_samples = 10\n",
    "x_t = model_without_time.sample(n_samples=n_samples, size=train_dataset[0][0].shape)\n",
    "grid = make_grid(x_t, nrow=10)\n",
    "save_image(grid, f\"epoch_without.png\")\n",
    "\n",
    "cols = 5\n",
    "rows = (n_samples // cols) + (0 if n_samples % cols == 0 else 1)\n",
    "fig, axs = plt.subplots(rows, cols, figsize=(3 * cols, 3 * rows))\n",
    "for i in range(x_t.shape[0]):\n",
    "    row = i // cols\n",
    "    axs[row, i % cols].imshow(x_t[i].permute(1,2,0).detach().cpu().numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IGNORE_TIME_EMB = False\n",
    "\n",
    "n_samples = 10\n",
    "x_t = model_with_time.sample(n_samples=n_samples, size=train_dataset[0][0].shape)\n",
    "grid = make_grid(x_t, nrow=10)\n",
    "save_image(grid, f\"epoch_without.png\")\n",
    "\n",
    "cols = 5\n",
    "rows = (n_samples // cols) + (0 if n_samples % cols == 0 else 1)\n",
    "fig, axs = plt.subplots(rows, cols, figsize=(3 * cols, 3 * rows))\n",
    "for i in range(x_t.shape[0]):\n",
    "    row = i // cols\n",
    "    axs[row, i % cols].imshow(x_t[i].permute(1,2,0).detach().cpu().numpy(), cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
